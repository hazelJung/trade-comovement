# 원본 데이터 기반 모델 비교 분석

## 📊 개요

원본 데이터(`value_sum`, 보정/클리핑 없음)를 사용하여 여러 모델을 학습하고 성능을 비교한 결과입니다.

## 🎯 모델 성능 비교

### Cross-Validation 결과 (Time Series Split, 3 folds)

| 모델 | MAE | RMSE | NMAE | 순위 |
|------|-----|------|------|------|
| **RandomForest** | **650,064** | **1,572,921** | **576,150,890,660** | 🥇 1위 |
| Ridge | 1,522,474 | 4,465,957 | 1,000,698,279,473 | 🥈 2위 |
| Quantile | 5,081,291 | 15,732,015 | 2,166,873,365,354 | 🥉 3위 |

### 상세 분석

#### 1. RandomForest (최고 성능) 🏆

**장점:**
- ✅ **가장 낮은 MAE**: 650,064 (Ridge의 42.7%)
- ✅ **가장 낮은 RMSE**: 1,572,921 (Ridge의 35.2%)
- ✅ **비선형 관계 학습**: 원본 데이터의 복잡한 패턴을 잘 포착
- ✅ **피처 중요도 분석 가능**: 어떤 피처가 중요한지 확인 가능

**단점:**
- ⚠️ 학습 시간이 상대적으로 김
- ⚠️ 하이퍼파라미터 튜닝 필요 (현재: n_estimators=100, max_depth=10)

**특징:**
- 원본 데이터의 극단값과 비선형 패턴을 잘 처리
- 여러 트리의 앙상블로 안정적인 예측

#### 2. Ridge Regression (2위)

**장점:**
- ✅ 빠른 학습 속도
- ✅ 해석 가능한 계수
- ✅ 정규화로 과적합 방지

**단점:**
- ⚠️ 선형 관계만 학습 가능
- ⚠️ 극단값에 민감할 수 있음

**특징:**
- 원본 데이터의 선형 관계를 잘 포착
- 안정적이고 빠른 예측

#### 3. Quantile Regression (3위)

**장점:**
- ✅ 중앙값 예측에 특화
- ✅ 이상치에 덜 민감

**단점:**
- ⚠️ 이 데이터셋에서는 성능이 낮음
- ⚠️ 학습 시간이 상대적으로 김

**특징:**
- NMAE 최적화에 유리할 수 있지만, 이 경우에는 RandomForest가 더 좋음

## 📈 성능 지표 해석

### MAE (Mean Absolute Error)
- **RandomForest**: 650,064
  - 평균적으로 약 65만원의 오차
  - 가장 정확한 예측

### RMSE (Root Mean Squared Error)
- **RandomForest**: 1,572,921
  - 큰 오차에 더 큰 패널티를 주는 지표
  - RandomForest가 극단값도 잘 예측

### NMAE (Normalized Mean Absolute Error)
- **주의**: NMAE 값이 매우 큰 이유는 0에 가까운 값으로 나누는 경우가 많아서입니다.
- 실제 평가에서는 F1 Score와 함께 고려해야 합니다.

## 🎯 최종 추천 모델

### **RandomForest 추천** ✅

**이유:**
1. **가장 낮은 오차**: MAE와 RMSE 모두 최고
2. **원본 데이터 특성**: 극단값과 비선형 패턴을 잘 처리
3. **안정성**: 여러 트리의 앙상블로 안정적인 예측

### 모델 선택 가이드

| 상황 | 추천 모델 |
|------|----------|
| **최고 성능 필요** | RandomForest |
| **빠른 학습 필요** | Ridge |
| **해석 가능성 중요** | Ridge |
| **극단값이 많은 데이터** | RandomForest |
| **선형 관계가 명확한 경우** | Ridge |

## 📊 원본 데이터 vs 보정 데이터 비교

### 원본 데이터 (현재 모델)
- ✅ 실제 데이터 그대로 사용
- ✅ 정보 손실 없음
- ✅ 극단값 포함

### 보정 데이터 (기존 모델)
- ✅ 결측치 보정으로 데이터 품질 향상
- ✅ 극단값 클리핑으로 안정성 향상
- ⚠️ 정보 손실 가능성

## 🔧 하이퍼파라미터 튜닝 권장사항

### RandomForest
```python
# 현재 설정
n_estimators=100
max_depth=10

# 튜닝 가능한 옵션
- n_estimators: 200, 300 (더 많은 트리)
- max_depth: 15, 20 (더 깊은 트리)
- min_samples_split: 2, 5 (분할 최소 샘플 수)
- min_samples_leaf: 1, 2 (리프 최소 샘플 수)
```

### Ridge
```python
# 현재 설정
alpha=1.0

# 튜닝 가능한 옵션
- alpha: 0.1, 0.5, 2.0, 10.0 (정규화 강도)
```

## 📝 결론

1. **원본 데이터로 학습한 모델 중에서는 RandomForest가 최고 성능**
2. **MAE 기준으로 Ridge보다 약 57% 더 정확**
3. **원본 데이터의 비선형 패턴을 잘 포착**
4. **추가 하이퍼파라미터 튜닝으로 성능 향상 가능**

## 🚀 다음 단계

1. **RandomForest 하이퍼파라미터 튜닝**
   - GridSearchCV 또는 RandomSearchCV 사용
   - n_estimators, max_depth 최적화

2. **앙상블 모델 시도**
   - RandomForest + Ridge 앙상블
   - Voting 또는 Stacking

3. **피처 엔지니어링**
   - 변동성 지표 추가
   - 시계열 특성 추가

4. **XGBoost 추가 비교**
   - XGBoost 설치 후 성능 비교
   - LightGBM도 고려

---

**생성일**: 2024-11-18  
**모델 파일**: `models/train_model_original_data.py`  
**제출 파일**: `results/submissions/original_data_submit.csv`

